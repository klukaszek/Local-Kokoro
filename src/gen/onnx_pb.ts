//
// WARNING: This file is automatically generated!  Please edit onnx.in.proto.
//

// SPDX-License-Identifier: Apache-2.0

// @generated by protoc-gen-es v2.2.3 with parameter "target=ts"
// @generated from file onnx.proto (package onnx, syntax proto3)
/* eslint-disable */

import type { GenEnum, GenFile, GenMessage } from "@bufbuild/protobuf/codegenv1";
import { enumDesc, fileDesc, messageDesc } from "@bufbuild/protobuf/codegenv1";
import type { Message } from "@bufbuild/protobuf";

/**
 * Describes the file onnx.proto.
 */
export const file_onnx: GenFile = /*@__PURE__*/
  fileDesc("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");

/**
 * Attributes
 *
 * A named attribute containing either singular float, integer, string, graph,
 * and tensor values, or repeated float, integer, string, graph, and tensor values.
 * An AttributeProto MUST contain the name field, and *only one* of the
 * following content fields, effectively enforcing a C/C++ union equivalent.
 *
 * @generated from message onnx.AttributeProto
 */
export type AttributeProto = Message<"onnx.AttributeProto"> & {
  /**
   * The name field MUST be present for this version of the IR.
   *
   * namespace Attribute
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * if ref_attr_name is not empty, ref_attr_name is the attribute name in parent function.
   * In this case, this AttributeProto does not contain data, and it's a reference of attribute
   * in parent scope.
   * NOTE: This should ONLY be used in function (sub-graph). It's invalid to be used in main graph.
   *
   * @generated from field: string ref_attr_name = 21;
   */
  refAttrName: string;

  /**
   * A human-readable documentation for this attribute. Markdown is allowed.
   *
   * @generated from field: string doc_string = 13;
   */
  docString: string;

  /**
   * The type field MUST be present for this version of the IR.
   * For 0.0.1 versions of the IR, this field was not defined, and
   * implementations needed to use has_field heuristics to determine
   * which value field was in use.  For IR_VERSION 0.0.2 or later, this
   * field MUST be set and match the f|i|s|t|... field in use.  This
   * change was made to accommodate proto3 implementations.
   *
   * discriminator that indicates which field below is in use
   *
   * @generated from field: onnx.AttributeProto.AttributeType type = 20;
   */
  type: AttributeProto_AttributeType;

  /**
   * Exactly ONE of the following fields must be present for this version of the IR
   *
   * float
   *
   * @generated from field: float f = 2;
   */
  f: number;

  /**
   * int
   *
   * @generated from field: int64 i = 3;
   */
  i: bigint;

  /**
   * UTF-8 string
   *
   * @generated from field: bytes s = 4;
   */
  s: Uint8Array;

  /**
   * tensor value
   *
   * @generated from field: onnx.TensorProto t = 5;
   */
  t?: TensorProto;

  /**
   * graph
   *
   * @generated from field: onnx.GraphProto g = 6;
   */
  g?: GraphProto;

  /**
   * sparse tensor value
   *
   * @generated from field: onnx.SparseTensorProto sparse_tensor = 22;
   */
  sparseTensor?: SparseTensorProto;

  /**
   * Do not use field below, it's deprecated.
   * optional ValueProto v = 12;         // value - subsumes everything but graph
   *
   * type proto
   *
   * @generated from field: onnx.TypeProto tp = 14;
   */
  tp?: TypeProto;

  /**
   * list of floats
   *
   * @generated from field: repeated float floats = 7;
   */
  floats: number[];

  /**
   * list of ints
   *
   * @generated from field: repeated int64 ints = 8;
   */
  ints: bigint[];

  /**
   * list of UTF-8 strings
   *
   * @generated from field: repeated bytes strings = 9;
   */
  strings: Uint8Array[];

  /**
   * list of tensors
   *
   * @generated from field: repeated onnx.TensorProto tensors = 10;
   */
  tensors: TensorProto[];

  /**
   * list of graph
   *
   * @generated from field: repeated onnx.GraphProto graphs = 11;
   */
  graphs: GraphProto[];

  /**
   * list of sparse tensors
   *
   * @generated from field: repeated onnx.SparseTensorProto sparse_tensors = 23;
   */
  sparseTensors: SparseTensorProto[];

  /**
   * list of type protos
   *
   * @generated from field: repeated onnx.TypeProto type_protos = 15;
   */
  typeProtos: TypeProto[];
};

/**
 * Describes the message onnx.AttributeProto.
 * Use `create(AttributeProtoSchema)` to create a new message.
 */
export const AttributeProtoSchema: GenMessage<AttributeProto> = /*@__PURE__*/
  messageDesc(file_onnx, 0);

/**
 * Note: this enum is structurally identical to the OpSchema::AttrType
 * enum defined in schema.h.  If you rev one, you likely need to rev the other.
 *
 * @generated from enum onnx.AttributeProto.AttributeType
 */
export enum AttributeProto_AttributeType {
  /**
   * @generated from enum value: UNDEFINED = 0;
   */
  UNDEFINED = 0,

  /**
   * @generated from enum value: FLOAT = 1;
   */
  FLOAT = 1,

  /**
   * @generated from enum value: INT = 2;
   */
  INT = 2,

  /**
   * @generated from enum value: STRING = 3;
   */
  STRING = 3,

  /**
   * @generated from enum value: TENSOR = 4;
   */
  TENSOR = 4,

  /**
   * @generated from enum value: GRAPH = 5;
   */
  GRAPH = 5,

  /**
   * @generated from enum value: SPARSE_TENSOR = 11;
   */
  SPARSE_TENSOR = 11,

  /**
   * @generated from enum value: TYPE_PROTO = 13;
   */
  TYPE_PROTO = 13,

  /**
   * @generated from enum value: FLOATS = 6;
   */
  FLOATS = 6,

  /**
   * @generated from enum value: INTS = 7;
   */
  INTS = 7,

  /**
   * @generated from enum value: STRINGS = 8;
   */
  STRINGS = 8,

  /**
   * @generated from enum value: TENSORS = 9;
   */
  TENSORS = 9,

  /**
   * @generated from enum value: GRAPHS = 10;
   */
  GRAPHS = 10,

  /**
   * @generated from enum value: SPARSE_TENSORS = 12;
   */
  SPARSE_TENSORS = 12,

  /**
   * @generated from enum value: TYPE_PROTOS = 14;
   */
  TYPE_PROTOS = 14,
}

/**
 * Describes the enum onnx.AttributeProto.AttributeType.
 */
export const AttributeProto_AttributeTypeSchema: GenEnum<AttributeProto_AttributeType> = /*@__PURE__*/
  enumDesc(file_onnx, 0, 0);

/**
 * Defines information on value, including the name, the type, and
 * the shape of the value.
 *
 * @generated from message onnx.ValueInfoProto
 */
export type ValueInfoProto = Message<"onnx.ValueInfoProto"> & {
  /**
   * This field MUST be present in this version of the IR.
   *
   * namespace Value
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * This field MUST be present in this version of the IR for
   * inputs and outputs of the top-level graph.
   *
   * @generated from field: onnx.TypeProto type = 2;
   */
  type?: TypeProto;

  /**
   * A human-readable documentation for this value. Markdown is allowed.
   *
   * @generated from field: string doc_string = 3;
   */
  docString: string;

  /**
   * Named metadata values; keys should be distinct.
   *
   * @generated from field: repeated onnx.StringStringEntryProto metadata_props = 4;
   */
  metadataProps: StringStringEntryProto[];
};

/**
 * Describes the message onnx.ValueInfoProto.
 * Use `create(ValueInfoProtoSchema)` to create a new message.
 */
export const ValueInfoProtoSchema: GenMessage<ValueInfoProto> = /*@__PURE__*/
  messageDesc(file_onnx, 1);

/**
 * Nodes
 *
 * Computation graphs are made up of a DAG of nodes, which represent what is
 * commonly called a "layer" or "pipeline stage" in machine learning frameworks.
 *
 * For example, it can be a node of type "Conv" that takes in an image, a filter
 * tensor and a bias tensor, and produces the convolved output.
 *
 * @generated from message onnx.NodeProto
 */
export type NodeProto = Message<"onnx.NodeProto"> & {
  /**
   * namespace Value
   *
   * @generated from field: repeated string input = 1;
   */
  input: string[];

  /**
   * namespace Value
   *
   * @generated from field: repeated string output = 2;
   */
  output: string[];

  /**
   * An optional identifier for this node in a graph.
   * This field MAY be absent in this version of the IR.
   *
   * namespace Node
   *
   * @generated from field: string name = 3;
   */
  name: string;

  /**
   * The symbolic identifier of the Operator to execute.
   *
   * namespace Operator
   *
   * @generated from field: string op_type = 4;
   */
  opType: string;

  /**
   * The domain of the OperatorSet that specifies the operator named by op_type.
   *
   * namespace Domain
   *
   * @generated from field: string domain = 7;
   */
  domain: string;

  /**
   * Overload identifier, used only to map this to a model-local function.
   *
   * @generated from field: string overload = 8;
   */
  overload: string;

  /**
   * Additional named attributes.
   *
   * @generated from field: repeated onnx.AttributeProto attribute = 5;
   */
  attribute: AttributeProto[];

  /**
   * A human-readable documentation for this node. Markdown is allowed.
   *
   * @generated from field: string doc_string = 6;
   */
  docString: string;

  /**
   * Named metadata values; keys should be distinct.
   *
   * @generated from field: repeated onnx.StringStringEntryProto metadata_props = 9;
   */
  metadataProps: StringStringEntryProto[];
};

/**
 * Describes the message onnx.NodeProto.
 * Use `create(NodeProtoSchema)` to create a new message.
 */
export const NodeProtoSchema: GenMessage<NodeProto> = /*@__PURE__*/
  messageDesc(file_onnx, 2);

/**
 * Training information
 * TrainingInfoProto stores information for training a model.
 * In particular, this defines two functionalities: an initialization-step
 * and a training-algorithm-step. Initialization resets the model
 * back to its original state as if no training has been performed.
 * Training algorithm improves the model based on input data.
 *
 * The semantics of the initialization-step is that the initializers
 * in ModelProto.graph and in TrainingInfoProto.algorithm are first
 * initialized as specified by the initializers in the graph, and then
 * updated by the "initialization_binding" in every instance in
 * ModelProto.training_info.
 *
 * The field "algorithm" defines a computation graph which represents a
 * training algorithm's step. After the execution of a
 * TrainingInfoProto.algorithm, the initializers specified by "update_binding"
 * may be immediately updated. If the targeted training algorithm contains
 * consecutive update steps (such as block coordinate descent methods),
 * the user needs to create a TrainingInfoProto for each step.
 *
 * @generated from message onnx.TrainingInfoProto
 */
export type TrainingInfoProto = Message<"onnx.TrainingInfoProto"> & {
  /**
   * This field describes a graph to compute the initial tensors
   * upon starting the training process. Initialization graph has no input
   * and can have multiple outputs. Usually, trainable tensors in neural
   * networks are randomly initialized. To achieve that, for each tensor,
   * the user can put a random number operator such as RandomNormal or
   * RandomUniform in TrainingInfoProto.initialization.node and assign its
   * random output to the specific tensor using "initialization_binding".
   * This graph can also set the initializers in "algorithm" in the same
   * TrainingInfoProto; a use case is resetting the number of training
   * iteration to zero.
   *
   * By default, this field is an empty graph and its evaluation does not
   * produce any output. Thus, no initializer would be changed by default.
   *
   * @generated from field: onnx.GraphProto initialization = 1;
   */
  initialization?: GraphProto;

  /**
   * This field represents a training algorithm step. Given required inputs,
   * it computes outputs to update initializers in its own or inference graph's
   * initializer lists. In general, this field contains loss node, gradient node,
   * optimizer node, increment of iteration count.
   *
   * An execution of the training algorithm step is performed by executing the
   * graph obtained by combining the inference graph (namely "ModelProto.graph")
   * and the "algorithm" graph. That is, the actual
   * input/initializer/output/node/value_info/sparse_initializer list of
   * the training graph is the concatenation of
   * "ModelProto.graph.input/initializer/output/node/value_info/sparse_initializer"
   * and "algorithm.input/initializer/output/node/value_info/sparse_initializer"
   * in that order. This combined graph must satisfy the normal ONNX conditions.
   * Now, let's provide a visualization of graph combination for clarity.
   * Let the inference graph (i.e., "ModelProto.graph") be
   *    tensor_a, tensor_b -> MatMul -> tensor_c -> Sigmoid -> tensor_d
   * and the "algorithm" graph be
   *    tensor_d -> Add -> tensor_e
   * The combination process results
   *    tensor_a, tensor_b -> MatMul -> tensor_c -> Sigmoid -> tensor_d -> Add -> tensor_e
   *
   * Notice that an input of a node in the "algorithm" graph may reference the
   * output of a node in the inference graph (but not the other way round). Also, inference
   * node cannot reference inputs of "algorithm". With these restrictions, inference graph
   * can always be run independently without training information.
   *
   * By default, this field is an empty graph and its evaluation does not
   * produce any output. Evaluating the default training step never
   * update any initializers.
   *
   * @generated from field: onnx.GraphProto algorithm = 2;
   */
  algorithm?: GraphProto;

  /**
   * This field specifies the bindings from the outputs of "initialization" to
   * some initializers in "ModelProto.graph.initializer" and
   * the "algorithm.initializer" in the same TrainingInfoProto.
   * See "update_binding" below for details.
   *
   * By default, this field is empty and no initializer would be changed
   * by the execution of "initialization".
   *
   * @generated from field: repeated onnx.StringStringEntryProto initialization_binding = 3;
   */
  initializationBinding: StringStringEntryProto[];

  /**
   * Gradient-based training is usually an iterative procedure. In one gradient
   * descent iteration, we apply
   *
   * x = x - r * g
   *
   * where "x" is the optimized tensor, "r" stands for learning rate, and "g" is
   * gradient of "x" with respect to a chosen loss. To avoid adding assignments
   * into the training graph, we split the update equation into
   *
   * y = x - r * g
   * x = y
   *
   * The user needs to save "y = x - r * g" into TrainingInfoProto.algorithm. To
   * tell that "y" should be assigned to "x", the field "update_binding" may
   * contain a key-value pair of strings, "x" (key of StringStringEntryProto)
   * and "y" (value of StringStringEntryProto).
   * For a neural network with multiple trainable (mutable) tensors, there can
   * be multiple key-value pairs in "update_binding".
   *
   * The initializers appears as keys in "update_binding" are considered
   * mutable variables. This implies some behaviors
   * as described below.
   *
   *  1. We have only unique keys in all "update_binding"s so that two
   *     variables may not have the same name. This ensures that one
   *     variable is assigned up to once.
   *  2. The keys must appear in names of "ModelProto.graph.initializer" or
   *     "TrainingInfoProto.algorithm.initializer".
   *  3. The values must be output names of "algorithm" or "ModelProto.graph.output".
   *  4. Mutable variables are initialized to the value specified by the
   *     corresponding initializer, and then potentially updated by
   *     "initializer_binding"s and "update_binding"s in "TrainingInfoProto"s.
   *
   * This field usually contains names of trainable tensors
   * (in ModelProto.graph), optimizer states such as momentums in advanced
   * stochastic gradient methods (in TrainingInfoProto.graph),
   * and number of training iterations (in TrainingInfoProto.graph).
   *
   * By default, this field is empty and no initializer would be changed
   * by the execution of "algorithm".
   *
   * @generated from field: repeated onnx.StringStringEntryProto update_binding = 4;
   */
  updateBinding: StringStringEntryProto[];
};

/**
 * Describes the message onnx.TrainingInfoProto.
 * Use `create(TrainingInfoProtoSchema)` to create a new message.
 */
export const TrainingInfoProtoSchema: GenMessage<TrainingInfoProto> = /*@__PURE__*/
  messageDesc(file_onnx, 3);

/**
 * Models
 *
 * ModelProto is a top-level file/container format for bundling a ML model and
 * associating its computation graph with metadata.
 *
 * The semantics of the model are described by the associated GraphProto's.
 *
 * @generated from message onnx.ModelProto
 */
export type ModelProto = Message<"onnx.ModelProto"> & {
  /**
   * The version of the IR this model targets. See Version enum above.
   * This field MUST be present.
   *
   * @generated from field: int64 ir_version = 1;
   */
  irVersion: bigint;

  /**
   * The OperatorSets this model relies on.
   * All ModelProtos MUST have at least one entry that
   * specifies which version of the ONNX OperatorSet is
   * being imported.
   *
   * All nodes in the ModelProto's graph will bind against the operator
   * with the same-domain/same-op_type operator with the HIGHEST version
   * in the referenced operator sets.
   *
   * @generated from field: repeated onnx.OperatorSetIdProto opset_import = 8;
   */
  opsetImport: OperatorSetIdProto[];

  /**
   * The name of the framework or tool used to generate this model.
   * This field SHOULD be present to indicate which implementation/tool/framework
   * emitted the model.
   *
   * @generated from field: string producer_name = 2;
   */
  producerName: string;

  /**
   * The version of the framework or tool used to generate this model.
   * This field SHOULD be present to indicate which implementation/tool/framework
   * emitted the model.
   *
   * @generated from field: string producer_version = 3;
   */
  producerVersion: string;

  /**
   * Domain name of the model.
   * We use reverse domain names as name space indicators. For example:
   * `com.facebook.fair` or `com.microsoft.cognitiveservices`
   *
   * Together with `model_version` and GraphProto.name, this forms the unique identity of
   * the graph.
   *
   * @generated from field: string domain = 4;
   */
  domain: string;

  /**
   * The version of the graph encoded. See Version enum below.
   *
   * @generated from field: int64 model_version = 5;
   */
  modelVersion: bigint;

  /**
   * A human-readable documentation for this model. Markdown is allowed.
   *
   * @generated from field: string doc_string = 6;
   */
  docString: string;

  /**
   * The parameterized graph that is evaluated to execute the model.
   *
   * @generated from field: onnx.GraphProto graph = 7;
   */
  graph?: GraphProto;

  /**
   * Named metadata values; keys should be distinct.
   *
   * @generated from field: repeated onnx.StringStringEntryProto metadata_props = 14;
   */
  metadataProps: StringStringEntryProto[];

  /**
   * Training-specific information. Sequentially executing all stored
   * `TrainingInfoProto.algorithm`s and assigning their outputs following
   * the corresponding `TrainingInfoProto.update_binding`s is one training
   * iteration. Similarly, to initialize the model
   * (as if training hasn't happened), the user should sequentially execute
   * all stored `TrainingInfoProto.initialization`s and assigns their outputs
   * using `TrainingInfoProto.initialization_binding`s.
   *
   * If this field is empty, the training behavior of the model is undefined.
   *
   * @generated from field: repeated onnx.TrainingInfoProto training_info = 20;
   */
  trainingInfo: TrainingInfoProto[];

  /**
   * A list of function protos local to the model.
   *
   * The (domain, name, overload) tuple must be unique across the function protos in this list.
   * In case of any conflicts the behavior (whether the model local functions are given higher priority,
   * or standard operator sets are given higher priotity or this is treated as error) is defined by
   * the runtimes.
   *
   * The operator sets imported by FunctionProto should be compatible with the ones
   * imported by ModelProto and other model local FunctionProtos.
   * Example, if same operator set say 'A' is imported by a FunctionProto and ModelProto
   * or by 2 FunctionProtos then versions for the operator set may be different but,
   * the operator schema returned for op_type, domain, version combination
   * for both the versions should be same for every node in the function body.
   *
   * One FunctionProto can reference other FunctionProto in the model, however, recursive reference
   * is not allowed.
   *
   * @generated from field: repeated onnx.FunctionProto functions = 25;
   */
  functions: FunctionProto[];
};

/**
 * Describes the message onnx.ModelProto.
 * Use `create(ModelProtoSchema)` to create a new message.
 */
export const ModelProtoSchema: GenMessage<ModelProto> = /*@__PURE__*/
  messageDesc(file_onnx, 4);

/**
 * StringStringEntryProto follows the pattern for cross-proto-version maps.
 * See https://developers.google.com/protocol-buffers/docs/proto3#maps
 *
 * @generated from message onnx.StringStringEntryProto
 */
export type StringStringEntryProto = Message<"onnx.StringStringEntryProto"> & {
  /**
   * @generated from field: string key = 1;
   */
  key: string;

  /**
   * @generated from field: string value = 2;
   */
  value: string;
};

/**
 * Describes the message onnx.StringStringEntryProto.
 * Use `create(StringStringEntryProtoSchema)` to create a new message.
 */
export const StringStringEntryProtoSchema: GenMessage<StringStringEntryProto> = /*@__PURE__*/
  messageDesc(file_onnx, 5);

/**
 * @generated from message onnx.TensorAnnotation
 */
export type TensorAnnotation = Message<"onnx.TensorAnnotation"> & {
  /**
   * @generated from field: string tensor_name = 1;
   */
  tensorName: string;

  /**
   * <key, value> pairs to annotate tensor specified by <tensor_name> above.
   * The keys used in the mapping below must be pre-defined in ONNX spec.
   * For example, for 8-bit linear quantization case, 'SCALE_TENSOR', 'ZERO_POINT_TENSOR' will be pre-defined as
   * quantization parameter keys.
   *
   * @generated from field: repeated onnx.StringStringEntryProto quant_parameter_tensor_names = 2;
   */
  quantParameterTensorNames: StringStringEntryProto[];
};

/**
 * Describes the message onnx.TensorAnnotation.
 * Use `create(TensorAnnotationSchema)` to create a new message.
 */
export const TensorAnnotationSchema: GenMessage<TensorAnnotation> = /*@__PURE__*/
  messageDesc(file_onnx, 6);

/**
 * Graphs
 *
 * A graph defines the computational logic of a model and is comprised of a parameterized
 * list of nodes that form a directed acyclic graph based on their inputs and outputs.
 * This is the equivalent of the "network" or "graph" in many deep learning
 * frameworks.
 *
 * @generated from message onnx.GraphProto
 */
export type GraphProto = Message<"onnx.GraphProto"> & {
  /**
   * The nodes in the graph, sorted topologically.
   *
   * @generated from field: repeated onnx.NodeProto node = 1;
   */
  node: NodeProto[];

  /**
   * The name of the graph.
   *
   * namespace Graph
   *
   * @generated from field: string name = 2;
   */
  name: string;

  /**
   * A list of named tensor values, used to specify constant inputs of the graph.
   * Each initializer (both TensorProto as well SparseTensorProto) MUST have a name.
   * The name MUST be unique across both initializer and sparse_initializer,
   * but the name MAY also appear in the input list.
   *
   * @generated from field: repeated onnx.TensorProto initializer = 5;
   */
  initializer: TensorProto[];

  /**
   * Initializers (see above) stored in sparse format.
   *
   * @generated from field: repeated onnx.SparseTensorProto sparse_initializer = 15;
   */
  sparseInitializer: SparseTensorProto[];

  /**
   * A human-readable documentation for this graph. Markdown is allowed.
   *
   * @generated from field: string doc_string = 10;
   */
  docString: string;

  /**
   * The inputs and outputs of the graph.
   *
   * @generated from field: repeated onnx.ValueInfoProto input = 11;
   */
  input: ValueInfoProto[];

  /**
   * @generated from field: repeated onnx.ValueInfoProto output = 12;
   */
  output: ValueInfoProto[];

  /**
   * Information for the values in the graph. The ValueInfoProto.name's
   * must be distinct. It is optional for a value to appear in value_info list.
   *
   * @generated from field: repeated onnx.ValueInfoProto value_info = 13;
   */
  valueInfo: ValueInfoProto[];

  /**
   * This field carries information to indicate the mapping among a tensor and its
   * quantization parameter tensors. For example:
   * For tensor 'a', it may have {'SCALE_TENSOR', 'a_scale'} and {'ZERO_POINT_TENSOR', 'a_zero_point'} annotated,
   * which means, tensor 'a_scale' and tensor 'a_zero_point' are scale and zero point of tensor 'a' in the model.
   *
   * @generated from field: repeated onnx.TensorAnnotation quantization_annotation = 14;
   */
  quantizationAnnotation: TensorAnnotation[];

  /**
   * Named metadata values; keys should be distinct.
   *
   * @generated from field: repeated onnx.StringStringEntryProto metadata_props = 16;
   */
  metadataProps: StringStringEntryProto[];
};

/**
 * Describes the message onnx.GraphProto.
 * Use `create(GraphProtoSchema)` to create a new message.
 */
export const GraphProtoSchema: GenMessage<GraphProto> = /*@__PURE__*/
  messageDesc(file_onnx, 7);

/**
 * Tensors
 *
 * A serialized tensor value.
 *
 * @generated from message onnx.TensorProto
 */
export type TensorProto = Message<"onnx.TensorProto"> & {
  /**
   * The shape of the tensor.
   *
   * @generated from field: repeated int64 dims = 1;
   */
  dims: bigint[];

  /**
   * The data type of the tensor.
   * This field MUST have a valid TensorProto.DataType value
   *
   * @generated from field: int32 data_type = 2;
   */
  dataType: number;

  /**
   * @generated from field: onnx.TensorProto.Segment segment = 3;
   */
  segment?: TensorProto_Segment;

  /**
   * For float and complex64 values
   * Complex64 tensors are encoded as a single array of floats,
   * with the real components appearing in odd numbered positions,
   * and the corresponding imaginary component appearing in the
   * subsequent even numbered position. (e.g., [1.0 + 2.0i, 3.0 + 4.0i]
   * is encoded as [1.0, 2.0 ,3.0 ,4.0]
   * When this field is present, the data_type field MUST be FLOAT or COMPLEX64.
   *
   * @generated from field: repeated float float_data = 4 [packed = true];
   */
  floatData: number[];

  /**
   * For int32, uint8, int8, uint16, int16, uint4, int4, bool, float8 and float16 values
   * float16 and float8 values must be bit-wise converted to an uint16_t prior
   * to writing to the buffer.
   * uint4 and int4 values must be packed to 4bitx2 prior to writing to the buffer, the first element is stored in
   * the 4 LSB and the second element is stored in the 4 MSB.
   * When this field is present, the data_type field MUST be
   * INT32, INT16, INT8, INT4, UINT16, UINT8, UINT4, BOOL, FLOAT16, BFLOAT16, FLOAT8E4M3FN, FLOAT8E4M3FNUZ, FLOAT8E5M2, FLOAT8E5M2FNUZ
   *
   * @generated from field: repeated int32 int32_data = 5 [packed = true];
   */
  int32Data: number[];

  /**
   * For strings.
   * Each element of string_data is a UTF-8 encoded Unicode
   * string. No trailing null, no leading BOM. The protobuf "string"
   * scalar type is not used to match ML community conventions.
   * When this field is present, the data_type field MUST be STRING
   *
   * @generated from field: repeated bytes string_data = 6;
   */
  stringData: Uint8Array[];

  /**
   * For int64.
   * When this field is present, the data_type field MUST be INT64
   *
   * @generated from field: repeated int64 int64_data = 7 [packed = true];
   */
  int64Data: bigint[];

  /**
   * Optionally, a name for the tensor.
   *
   * namespace Value
   *
   * @generated from field: string name = 8;
   */
  name: string;

  /**
   * A human-readable documentation for this tensor. Markdown is allowed.
   *
   * @generated from field: string doc_string = 12;
   */
  docString: string;

  /**
   * Serializations can either use one of the fields above, or use this
   * raw bytes field. The only exception is the string case, where one is
   * required to store the content in the repeated bytes string_data field.
   *
   * When this raw_data field is used to store tensor value, elements MUST
   * be stored in as fixed-width, little-endian order.
   * Floating-point data types MUST be stored in IEEE 754 format.
   * Complex64 elements must be written as two consecutive FLOAT values, real component first.
   * Complex128 elements must be written as two consecutive DOUBLE values, real component first.
   * Boolean type MUST be written one byte per tensor element (00000001 for true, 00000000 for false).
   * uint4 and int4 values must be packed to 4bitx2, the first element is stored in the 4 LSB and the second element is stored in the 4 MSB.
   *
   * Note: the advantage of specific field rather than the raw_data field is
   * that in some cases (e.g. int data), protobuf does a better packing via
   * variable length storage, and may lead to smaller binary footprint.
   * When this field is present, the data_type field MUST NOT be STRING or UNDEFINED
   *
   * @generated from field: bytes raw_data = 9;
   */
  rawData: Uint8Array;

  /**
   * Data can be stored inside the protobuf file using type-specific fields or raw_data.
   * Alternatively, raw bytes data can be stored in an external file, using the external_data field.
   * external_data stores key-value pairs describing data location. Recognized keys are:
   * - "location" (required) - POSIX filesystem path relative to the directory where the ONNX
   *                           protobuf model was stored
   * - "offset" (optional) - position of byte at which stored data begins. Integer stored as string.
   *                         Offset values SHOULD be multiples 4096 (page size) to enable mmap support.
   * - "length" (optional) - number of bytes containing data. Integer stored as string.
   * - "checksum" (optional) - SHA1 digest of file specified in under 'location' key.
   *
   * @generated from field: repeated onnx.StringStringEntryProto external_data = 13;
   */
  externalData: StringStringEntryProto[];

  /**
   * If value not set, data is stored in raw_data (if set) otherwise in type-specified field.
   *
   * @generated from field: onnx.TensorProto.DataLocation data_location = 14;
   */
  dataLocation: TensorProto_DataLocation;

  /**
   * For double
   * Complex128 tensors are encoded as a single array of doubles,
   * with the real components appearing in odd numbered positions,
   * and the corresponding imaginary component appearing in the
   * subsequent even numbered position. (e.g., [1.0 + 2.0i, 3.0 + 4.0i]
   * is encoded as [1.0, 2.0 ,3.0 ,4.0]
   * When this field is present, the data_type field MUST be DOUBLE or COMPLEX128
   *
   * @generated from field: repeated double double_data = 10 [packed = true];
   */
  doubleData: number[];

  /**
   * For uint64 and uint32 values
   * When this field is present, the data_type field MUST be
   * UINT32 or UINT64
   *
   * @generated from field: repeated uint64 uint64_data = 11 [packed = true];
   */
  uint64Data: bigint[];

  /**
   * Named metadata values; keys should be distinct.
   *
   * @generated from field: repeated onnx.StringStringEntryProto metadata_props = 16;
   */
  metadataProps: StringStringEntryProto[];
};

/**
 * Describes the message onnx.TensorProto.
 * Use `create(TensorProtoSchema)` to create a new message.
 */
export const TensorProtoSchema: GenMessage<TensorProto> = /*@__PURE__*/
  messageDesc(file_onnx, 8);

/**
 * For very large tensors, we may want to store them in chunks, in which
 * case the following fields will specify the segment that is stored in
 * the current TensorProto.
 *
 * @generated from message onnx.TensorProto.Segment
 */
export type TensorProto_Segment = Message<"onnx.TensorProto.Segment"> & {
  /**
   * @generated from field: int64 begin = 1;
   */
  begin: bigint;

  /**
   * @generated from field: int64 end = 2;
   */
  end: bigint;
};

/**
 * Describes the message onnx.TensorProto.Segment.
 * Use `create(TensorProto_SegmentSchema)` to create a new message.
 */
export const TensorProto_SegmentSchema: GenMessage<TensorProto_Segment> = /*@__PURE__*/
  messageDesc(file_onnx, 8, 0);

/**
 * @generated from enum onnx.TensorProto.DataType
 */
export enum TensorProto_DataType {
  /**
   * @generated from enum value: UNDEFINED = 0;
   */
  UNDEFINED = 0,

  /**
   * Basic types.
   *
   * float
   *
   * @generated from enum value: FLOAT = 1;
   */
  FLOAT = 1,

  /**
   * uint8_t
   *
   * @generated from enum value: UINT8 = 2;
   */
  UINT8 = 2,

  /**
   * int8_t
   *
   * @generated from enum value: INT8 = 3;
   */
  INT8 = 3,

  /**
   * uint16_t
   *
   * @generated from enum value: UINT16 = 4;
   */
  UINT16 = 4,

  /**
   * int16_t
   *
   * @generated from enum value: INT16 = 5;
   */
  INT16 = 5,

  /**
   * int32_t
   *
   * @generated from enum value: INT32 = 6;
   */
  INT32 = 6,

  /**
   * int64_t
   *
   * @generated from enum value: INT64 = 7;
   */
  INT64 = 7,

  /**
   * string
   *
   * @generated from enum value: STRING = 8;
   */
  STRING = 8,

  /**
   * bool
   *
   * @generated from enum value: BOOL = 9;
   */
  BOOL = 9,

  /**
   * IEEE754 half-precision floating-point format (16 bits wide).
   * This format has 1 sign bit, 5 exponent bits, and 10 mantissa bits.
   *
   * @generated from enum value: FLOAT16 = 10;
   */
  FLOAT16 = 10,

  /**
   * @generated from enum value: DOUBLE = 11;
   */
  DOUBLE = 11,

  /**
   * @generated from enum value: UINT32 = 12;
   */
  UINT32 = 12,

  /**
   * @generated from enum value: UINT64 = 13;
   */
  UINT64 = 13,

  /**
   * complex with float32 real and imaginary components
   *
   * @generated from enum value: COMPLEX64 = 14;
   */
  COMPLEX64 = 14,

  /**
   * complex with float64 real and imaginary components
   *
   * @generated from enum value: COMPLEX128 = 15;
   */
  COMPLEX128 = 15,

  /**
   * Non-IEEE floating-point format based on IEEE754 single-precision
   * floating-point number truncated to 16 bits.
   * This format has 1 sign bit, 8 exponent bits, and 7 mantissa bits.
   *
   * @generated from enum value: BFLOAT16 = 16;
   */
  BFLOAT16 = 16,

  /**
   * Non-IEEE floating-point format based on papers
   * FP8 Formats for Deep Learning, https://arxiv.org/abs/2209.05433,
   * 8-bit Numerical Formats For Deep Neural Networks, https://arxiv.org/pdf/2206.02915.pdf.
   * Operators supported FP8 are Cast, CastLike, QuantizeLinear, DequantizeLinear.
   * The computation usually happens inside a block quantize / dequantize
   * fused by the runtime.
   *
   * float 8, mostly used for coefficients, supports nan, not inf
   *
   * @generated from enum value: FLOAT8E4M3FN = 17;
   */
  FLOAT8E4M3FN = 17,

  /**
   * float 8, mostly used for coefficients, supports nan, not inf, no negative zero
   *
   * @generated from enum value: FLOAT8E4M3FNUZ = 18;
   */
  FLOAT8E4M3FNUZ = 18,

  /**
   * follows IEEE 754, supports nan, inf, mostly used for gradients
   *
   * @generated from enum value: FLOAT8E5M2 = 19;
   */
  FLOAT8E5M2 = 19,

  /**
   * follows IEEE 754, supports nan, not inf, mostly used for gradients, no negative zero
   *
   * @generated from enum value: FLOAT8E5M2FNUZ = 20;
   */
  FLOAT8E5M2FNUZ = 20,

  /**
   * 4-bit data-types
   *
   * Unsigned integer in range [0, 15]
   *
   * @generated from enum value: UINT4 = 21;
   */
  UINT4 = 21,

  /**
   * Signed integer in range [-8, 7], using two's-complement representation
   *
   * @generated from enum value: INT4 = 22;
   */
  INT4 = 22,
}

/**
 * Describes the enum onnx.TensorProto.DataType.
 */
export const TensorProto_DataTypeSchema: GenEnum<TensorProto_DataType> = /*@__PURE__*/
  enumDesc(file_onnx, 8, 0);

/**
 * Location of the data for this tensor. MUST be one of:
 * - DEFAULT - data stored inside the protobuf message. Data is stored in raw_data (if set) otherwise in type-specified field.
 * - EXTERNAL - data stored in an external location as described by external_data field.
 *
 * @generated from enum onnx.TensorProto.DataLocation
 */
export enum TensorProto_DataLocation {
  /**
   * @generated from enum value: DEFAULT = 0;
   */
  DEFAULT = 0,

  /**
   * @generated from enum value: EXTERNAL = 1;
   */
  EXTERNAL = 1,
}

/**
 * Describes the enum onnx.TensorProto.DataLocation.
 */
export const TensorProto_DataLocationSchema: GenEnum<TensorProto_DataLocation> = /*@__PURE__*/
  enumDesc(file_onnx, 8, 1);

/**
 * A serialized sparse-tensor value
 *
 * @generated from message onnx.SparseTensorProto
 */
export type SparseTensorProto = Message<"onnx.SparseTensorProto"> & {
  /**
   * The sequence of non-default values are encoded as a tensor of shape [NNZ].
   * The default-value is zero for numeric tensors, and empty-string for string tensors.
   * values must have a non-empty name present which serves as a name for SparseTensorProto
   * when used in sparse_initializer list.
   *
   * @generated from field: onnx.TensorProto values = 1;
   */
  values?: TensorProto;

  /**
   * The indices of the non-default values, which may be stored in one of two formats.
   * (a) Indices can be a tensor of shape [NNZ, rank] with the [i,j]-th value
   * corresponding to the j-th index of the i-th value (in the values tensor).
   * (b) Indices can be a tensor of shape [NNZ], in which case the i-th value
   * must be the linearized-index of the i-th value (in the values tensor).
   * The linearized-index can be converted into an index tuple (k_1,...,k_rank)
   * using the shape provided below.
   * The indices must appear in ascending order without duplication.
   * In the first format, the ordering is lexicographic-ordering:
   * e.g., index-value [1,4] must appear before [2,1]
   *
   * @generated from field: onnx.TensorProto indices = 2;
   */
  indices?: TensorProto;

  /**
   * The shape of the underlying dense-tensor: [dim_1, dim_2, ... dim_rank]
   *
   * @generated from field: repeated int64 dims = 3;
   */
  dims: bigint[];
};

/**
 * Describes the message onnx.SparseTensorProto.
 * Use `create(SparseTensorProtoSchema)` to create a new message.
 */
export const SparseTensorProtoSchema: GenMessage<SparseTensorProto> = /*@__PURE__*/
  messageDesc(file_onnx, 9);

/**
 * Defines a tensor shape. A dimension can be either an integer value
 * or a symbolic variable. A symbolic variable represents an unknown
 * dimension.
 *
 * @generated from message onnx.TensorShapeProto
 */
export type TensorShapeProto = Message<"onnx.TensorShapeProto"> & {
  /**
   * @generated from field: repeated onnx.TensorShapeProto.Dimension dim = 1;
   */
  dim: TensorShapeProto_Dimension[];
};

/**
 * Describes the message onnx.TensorShapeProto.
 * Use `create(TensorShapeProtoSchema)` to create a new message.
 */
export const TensorShapeProtoSchema: GenMessage<TensorShapeProto> = /*@__PURE__*/
  messageDesc(file_onnx, 10);

/**
 * @generated from message onnx.TensorShapeProto.Dimension
 */
export type TensorShapeProto_Dimension = Message<"onnx.TensorShapeProto.Dimension"> & {
  /**
   * @generated from oneof onnx.TensorShapeProto.Dimension.value
   */
  value: {
    /**
     * @generated from field: int64 dim_value = 1;
     */
    value: bigint;
    case: "dimValue";
  } | {
    /**
     * namespace Shape
     *
     * @generated from field: string dim_param = 2;
     */
    value: string;
    case: "dimParam";
  } | { case: undefined; value?: undefined };

  /**
   * Standard denotation can optionally be used to denote tensor
   * dimensions with standard semantic descriptions to ensure
   * that operations are applied to the correct axis of a tensor.
   * Refer to https://github.com/onnx/onnx/blob/main/docs/DimensionDenotation.md#denotation-definition
   * for pre-defined dimension denotations.
   *
   * @generated from field: string denotation = 3;
   */
  denotation: string;
};

/**
 * Describes the message onnx.TensorShapeProto.Dimension.
 * Use `create(TensorShapeProto_DimensionSchema)` to create a new message.
 */
export const TensorShapeProto_DimensionSchema: GenMessage<TensorShapeProto_Dimension> = /*@__PURE__*/
  messageDesc(file_onnx, 10, 0);

/**
 * Types
 *
 * The standard ONNX data types.
 *
 * @generated from message onnx.TypeProto
 */
export type TypeProto = Message<"onnx.TypeProto"> & {
  /**
   * @generated from oneof onnx.TypeProto.value
   */
  value: {
    /**
     * The type of a tensor.
     *
     * @generated from field: onnx.TypeProto.Tensor tensor_type = 1;
     */
    value: TypeProto_Tensor;
    case: "tensorType";
  } | {
    /**
     * The type of a sequence.
     *
     * @generated from field: onnx.TypeProto.Sequence sequence_type = 4;
     */
    value: TypeProto_Sequence;
    case: "sequenceType";
  } | {
    /**
     * The type of a map.
     *
     * @generated from field: onnx.TypeProto.Map map_type = 5;
     */
    value: TypeProto_Map;
    case: "mapType";
  } | {
    /**
     * The type of an optional.
     *
     * @generated from field: onnx.TypeProto.Optional optional_type = 9;
     */
    value: TypeProto_Optional;
    case: "optionalType";
  } | {
    /**
     * Type of the sparse tensor
     *
     * @generated from field: onnx.TypeProto.SparseTensor sparse_tensor_type = 8;
     */
    value: TypeProto_SparseTensor;
    case: "sparseTensorType";
  } | { case: undefined; value?: undefined };

  /**
   * An optional denotation can be used to denote the whole
   * type with a standard semantic description as to what is
   * stored inside. Refer to https://github.com/onnx/onnx/blob/main/docs/TypeDenotation.md#type-denotation-definition
   * for pre-defined type denotations.
   *
   * @generated from field: string denotation = 6;
   */
  denotation: string;
};

/**
 * Describes the message onnx.TypeProto.
 * Use `create(TypeProtoSchema)` to create a new message.
 */
export const TypeProtoSchema: GenMessage<TypeProto> = /*@__PURE__*/
  messageDesc(file_onnx, 11);

/**
 * @generated from message onnx.TypeProto.Tensor
 */
export type TypeProto_Tensor = Message<"onnx.TypeProto.Tensor"> & {
  /**
   * This field MUST NOT have the value of UNDEFINED
   * This field MUST have a valid TensorProto.DataType value
   * This field MUST be present for this version of the IR.
   *
   * @generated from field: int32 elem_type = 1;
   */
  elemType: number;

  /**
   * @generated from field: onnx.TensorShapeProto shape = 2;
   */
  shape?: TensorShapeProto;
};

/**
 * Describes the message onnx.TypeProto.Tensor.
 * Use `create(TypeProto_TensorSchema)` to create a new message.
 */
export const TypeProto_TensorSchema: GenMessage<TypeProto_Tensor> = /*@__PURE__*/
  messageDesc(file_onnx, 11, 0);

/**
 * repeated T
 *
 * @generated from message onnx.TypeProto.Sequence
 */
export type TypeProto_Sequence = Message<"onnx.TypeProto.Sequence"> & {
  /**
   * The type and optional shape of each element of the sequence.
   * This field MUST be present for this version of the IR.
   *
   * @generated from field: onnx.TypeProto elem_type = 1;
   */
  elemType?: TypeProto;
};

/**
 * Describes the message onnx.TypeProto.Sequence.
 * Use `create(TypeProto_SequenceSchema)` to create a new message.
 */
export const TypeProto_SequenceSchema: GenMessage<TypeProto_Sequence> = /*@__PURE__*/
  messageDesc(file_onnx, 11, 1);

/**
 * map<K,V>
 *
 * @generated from message onnx.TypeProto.Map
 */
export type TypeProto_Map = Message<"onnx.TypeProto.Map"> & {
  /**
   * This field MUST have a valid TensorProto.DataType value
   * This field MUST be present for this version of the IR.
   * This field MUST refer to an integral type ([U]INT{8|16|32|64}) or STRING
   *
   * @generated from field: int32 key_type = 1;
   */
  keyType: number;

  /**
   * This field MUST be present for this version of the IR.
   *
   * @generated from field: onnx.TypeProto value_type = 2;
   */
  valueType?: TypeProto;
};

/**
 * Describes the message onnx.TypeProto.Map.
 * Use `create(TypeProto_MapSchema)` to create a new message.
 */
export const TypeProto_MapSchema: GenMessage<TypeProto_Map> = /*@__PURE__*/
  messageDesc(file_onnx, 11, 2);

/**
 * wrapper for Tensor, Sequence, or Map
 *
 * @generated from message onnx.TypeProto.Optional
 */
export type TypeProto_Optional = Message<"onnx.TypeProto.Optional"> & {
  /**
   * The type and optional shape of the element wrapped.
   * This field MUST be present for this version of the IR.
   * Possible values correspond to OptionalProto.DataType enum
   *
   * @generated from field: onnx.TypeProto elem_type = 1;
   */
  elemType?: TypeProto;
};

/**
 * Describes the message onnx.TypeProto.Optional.
 * Use `create(TypeProto_OptionalSchema)` to create a new message.
 */
export const TypeProto_OptionalSchema: GenMessage<TypeProto_Optional> = /*@__PURE__*/
  messageDesc(file_onnx, 11, 3);

/**
 * @generated from message onnx.TypeProto.SparseTensor
 */
export type TypeProto_SparseTensor = Message<"onnx.TypeProto.SparseTensor"> & {
  /**
   * This field MUST NOT have the value of UNDEFINED
   * This field MUST have a valid TensorProto.DataType value
   * This field MUST be present for this version of the IR.
   *
   * @generated from field: int32 elem_type = 1;
   */
  elemType: number;

  /**
   * @generated from field: onnx.TensorShapeProto shape = 2;
   */
  shape?: TensorShapeProto;
};

/**
 * Describes the message onnx.TypeProto.SparseTensor.
 * Use `create(TypeProto_SparseTensorSchema)` to create a new message.
 */
export const TypeProto_SparseTensorSchema: GenMessage<TypeProto_SparseTensor> = /*@__PURE__*/
  messageDesc(file_onnx, 11, 4);

/**
 * Operator Sets
 *
 * OperatorSets are uniquely identified by a (domain, opset_version) pair.
 *
 * @generated from message onnx.OperatorSetIdProto
 */
export type OperatorSetIdProto = Message<"onnx.OperatorSetIdProto"> & {
  /**
   * The domain of the operator set being identified.
   * The empty string ("") or absence of this field implies the operator
   * set that is defined as part of the ONNX specification.
   * This field MUST be present in this version of the IR when referring to any other operator set.
   *
   * @generated from field: string domain = 1;
   */
  domain: string;

  /**
   * The version of the operator set being identified.
   * This field MUST be present in this version of the IR.
   *
   * @generated from field: int64 version = 2;
   */
  version: bigint;
};

/**
 * Describes the message onnx.OperatorSetIdProto.
 * Use `create(OperatorSetIdProtoSchema)` to create a new message.
 */
export const OperatorSetIdProtoSchema: GenMessage<OperatorSetIdProto> = /*@__PURE__*/
  messageDesc(file_onnx, 12);

/**
 * @generated from message onnx.FunctionProto
 */
export type FunctionProto = Message<"onnx.FunctionProto"> & {
  /**
   * The name of the function, similar to op_type in NodeProto.
   * This is part of the unique-id (domain, name, overload) of FunctionProtos in a model.
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * The inputs and outputs of the function.
   *
   * @generated from field: repeated string input = 4;
   */
  input: string[];

  /**
   * @generated from field: repeated string output = 5;
   */
  output: string[];

  /**
   * The attribute parameters of the function.
   * It is for function parameters without default values.
   *
   * @generated from field: repeated string attribute = 6;
   */
  attribute: string[];

  /**
   * The attribute protos of the function.
   * It is for function attributes with default values.
   * A function attribute shall be represented either as
   * a string attribute or an AttributeProto, not both.
   *
   * @generated from field: repeated onnx.AttributeProto attribute_proto = 11;
   */
  attributeProto: AttributeProto[];

  /**
   * The nodes in the function.
   *
   * @generated from field: repeated onnx.NodeProto node = 7;
   */
  node: NodeProto[];

  /**
   * A human-readable documentation for this function. Markdown is allowed.
   *
   * @generated from field: string doc_string = 8;
   */
  docString: string;

  /**
   * @generated from field: repeated onnx.OperatorSetIdProto opset_import = 9;
   */
  opsetImport: OperatorSetIdProto[];

  /**
   * The domain which this function belongs to.
   * This is part of the unique-id (domain, name, overload) of FunctionProtos in a model.
   *
   * @generated from field: string domain = 10;
   */
  domain: string;

  /**
   * The overload identifier of the function.
   * This is part of the unique-id (domain, name, overload) of FunctionProtos in a model.
   *
   * @generated from field: string overload = 13;
   */
  overload: string;

  /**
   * Information for the values in the function. The ValueInfoProto.name's
   * must be distinct and refer to names in the function (including inputs,
   * outputs, and intermediate values). It is optional for a value to appear
   * in value_info list.
   *
   * @generated from field: repeated onnx.ValueInfoProto value_info = 12;
   */
  valueInfo: ValueInfoProto[];

  /**
   * Named metadata values; keys should be distinct.
   *
   * @generated from field: repeated onnx.StringStringEntryProto metadata_props = 14;
   */
  metadataProps: StringStringEntryProto[];
};

/**
 * Describes the message onnx.FunctionProto.
 * Use `create(FunctionProtoSchema)` to create a new message.
 */
export const FunctionProtoSchema: GenMessage<FunctionProto> = /*@__PURE__*/
  messageDesc(file_onnx, 13);

/**
 * Versioning
 *
 * ONNX versioning is specified in docs/IR.md and elaborated on in docs/Versioning.md
 *
 * To be compatible with both proto2 and proto3, we will use a version number
 * that is not defined by the default value but an explicit enum number.
 *
 * @generated from enum onnx.Version
 */
export enum Version {
  /**
   * proto3 requires the first enum value to be zero.
   * We add this just to appease the compiler.
   *
   * @generated from enum value: _START_VERSION = 0;
   */
  _START_VERSION = 0,

  /**
   * The version field is always serialized and we will use it to store the
   * version that the  graph is generated from. This helps us set up version
   * control.
   * For the IR, we are using simple numbers starting with 0x00000001,
   * which was the version we published on Oct 10, 2017.
   *
   * @generated from enum value: IR_VERSION_2017_10_10 = 1;
   */
  IR_VERSION_2017_10_10 = 1,

  /**
   * IR_VERSION 2 published on Oct 30, 2017
   * - Added type discriminator to AttributeProto to support proto3 users
   *
   * @generated from enum value: IR_VERSION_2017_10_30 = 2;
   */
  IR_VERSION_2017_10_30 = 2,

  /**
   * IR VERSION 3 published on Nov 3, 2017
   * - For operator versioning:
   *    - Added new message OperatorSetIdProto
   *    - Added opset_import in ModelProto
   * - For vendor extensions, added domain in NodeProto
   *
   * @generated from enum value: IR_VERSION_2017_11_3 = 3;
   */
  IR_VERSION_2017_11_3 = 3,

  /**
   * IR VERSION 4 published on Jan 22, 2019
   * - Relax constraint that initializers should be a subset of graph inputs
   * - Add type BFLOAT16
   *
   * @generated from enum value: IR_VERSION_2019_1_22 = 4;
   */
  IR_VERSION_2019_1_22 = 4,

  /**
   * IR VERSION 5 published on March 18, 2019
   * - Add message TensorAnnotation.
   * - Add quantization annotation in GraphProto to map tensor with its scale and zero point quantization parameters.
   *
   * @generated from enum value: IR_VERSION_2019_3_18 = 5;
   */
  IR_VERSION_2019_3_18 = 5,

  /**
   * IR VERSION 6 published on Sep 19, 2019
   * - Add support for sparse tensor constants stored in model.
   *   - Add message SparseTensorProto
   *   - Add sparse initializers
   *
   * @generated from enum value: IR_VERSION_2019_9_19 = 6;
   */
  IR_VERSION_2019_9_19 = 6,

  /**
   * IR VERSION 7 published on May 8, 2020
   * - Add support to allow function body graph to rely on multiple external opreator sets.
   * - Add a list to promote inference graph's initializers to global and
   *   mutable variables. Global variables are visible in all graphs of the
   *   stored models.
   * - Add message TrainingInfoProto to store initialization
   *   method and training algorithm. The execution of TrainingInfoProto
   *   can modify the values of mutable variables.
   * - Implicitly add inference graph into each TrainingInfoProto's algorithm.
   *
   * @generated from enum value: IR_VERSION_2020_5_8 = 7;
   */
  IR_VERSION_2020_5_8 = 7,

  /**
   * IR VERSION 8 published on July 30, 2021
   * Introduce TypeProto.SparseTensor
   * Introduce TypeProto.Optional
   * Added a list of FunctionProtos local to the model
   * Deprecated since_version and operator status from FunctionProto
   *
   * @generated from enum value: IR_VERSION_2021_7_30 = 8;
   */
  IR_VERSION_2021_7_30 = 8,

  /**
   * IR VERSION 9 published on May 5, 2023
   * Added AttributeProto to FunctionProto so that default attribute values can be set.
   * Added FLOAT8E4M3FN, FLOAT8E4M3FNUZ, FLOAT8E5M2, FLOAT8E5M2FNUZ.
   *
   * @generated from enum value: IR_VERSION_2023_5_5 = 9;
   */
  IR_VERSION_2023_5_5 = 9,

  /**
   * IR VERSION 10 published on TBD
   * Added UINT4, INT4.
   *
   * @generated from enum value: IR_VERSION = 10;
   */
  IR_VERSION = 10,
}

/**
 * Describes the enum onnx.Version.
 */
export const VersionSchema: GenEnum<Version> = /*@__PURE__*/
  enumDesc(file_onnx, 0);

/**
 * Operator/function status.
 *
 * @generated from enum onnx.OperatorStatus
 */
export enum OperatorStatus {
  /**
   * @generated from enum value: EXPERIMENTAL = 0;
   */
  EXPERIMENTAL = 0,

  /**
   * @generated from enum value: STABLE = 1;
   */
  STABLE = 1,
}

/**
 * Describes the enum onnx.OperatorStatus.
 */
export const OperatorStatusSchema: GenEnum<OperatorStatus> = /*@__PURE__*/
  enumDesc(file_onnx, 1);

